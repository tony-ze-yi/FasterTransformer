INFO: Configuring Model for Quantization
INFO: using quantization package /opt/conda/lib/python3.8/site-packages/pytorch_quantization/__init__.py
INFO: Warning: changing transformer.encoder.layer.0.layernorm_input1_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.0.add1_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.0.add1_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.0.layernorm_input2_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.0.add2_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.0.add2_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.1.layernorm_input1_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.1.add1_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.1.add1_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.1.layernorm_input2_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.1.add2_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.1.add2_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.2.layernorm_input1_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.2.add1_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.2.add1_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.2.layernorm_input2_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.2.add2_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.2.add2_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.3.layernorm_input1_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.3.add1_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.3.add1_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.3.layernorm_input2_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.3.add2_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.3.add2_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.4.layernorm_input1_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.4.add1_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.4.add1_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.4.layernorm_input2_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.4.add2_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.4.add2_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.5.layernorm_input1_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.5.add1_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.5.add1_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.5.layernorm_input2_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.5.add2_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.5.add2_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.6.layernorm_input1_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.6.add1_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.6.add1_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.6.layernorm_input2_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.6.add2_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.6.add2_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.7.layernorm_input1_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.7.add1_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.7.add1_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.7.layernorm_input2_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.7.add2_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.7.add2_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.8.layernorm_input1_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.8.add1_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.8.add1_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.8.layernorm_input2_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.8.add2_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.8.add2_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.9.layernorm_input1_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.9.add1_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.9.add1_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.9.layernorm_input2_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.9.add2_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.9.add2_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.10.layernorm_input1_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.10.add1_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.10.add1_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.10.layernorm_input2_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.10.add2_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.10.add2_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.11.layernorm_input1_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.11.add1_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.11.add1_residual_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.11.layernorm_input2_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.11.add2_local_input_quantizer _disabled=True
INFO: Warning: changing transformer.encoder.layer.11.add2_residual_input_quantizer _disabled=True
INFO: FUSE_QKV: transformer.encoder.layer.0.attn                  
INFO:           q= 4.6758 k= 4.6758 v= 4.6758 ->  4.6758
INFO:           q= 0.3530 k= 0.3530 v= 0.3530 ->  0.3530
INFO:           q= 4.6016 k= 4.6016 v= 4.6016 ->  4.6016
INFO: FUSE_QKV: transformer.encoder.layer.1.attn                  
INFO:           q= 4.0234 k= 4.0234 v= 4.0234 ->  4.0234
INFO:           q= 0.3779 k= 0.3779 v= 0.3779 ->  0.3779
INFO:           q= 3.9648 k= 3.9648 v= 3.9648 ->  3.9648
INFO: FUSE_QKV: transformer.encoder.layer.2.attn                  
INFO:           q= 3.6328 k= 3.6328 v= 3.6328 ->  3.6328
INFO:           q= 0.3115 k= 0.3115 v= 0.3115 ->  0.3115
INFO:           q= 3.5762 k= 3.5762 v= 3.5762 ->  3.5762
INFO: FUSE_QKV: transformer.encoder.layer.3.attn                  
INFO:           q= 3.3457 k= 3.3457 v= 3.3457 ->  3.3457
INFO:           q= 0.3596 k= 0.3596 v= 0.3596 ->  0.3596
INFO:           q= 3.2988 k= 3.2988 v= 3.2988 ->  3.2988
INFO: FUSE_QKV: transformer.encoder.layer.4.attn                  
INFO:           q= 3.2832 k= 3.2832 v= 3.2832 ->  3.2832
INFO:           q= 0.3701 k= 0.3701 v= 0.3701 ->  0.3701
INFO:           q= 3.2891 k= 3.2891 v= 3.2891 ->  3.2891
INFO: FUSE_QKV: transformer.encoder.layer.5.attn                  
INFO:           q= 3.3574 k= 3.3574 v= 3.3574 ->  3.3574
INFO:           q= 0.3071 k= 0.3071 v= 0.3071 ->  0.3071
INFO:           q= 3.3535 k= 3.3535 v= 3.3535 ->  3.3535
INFO: FUSE_QKV: transformer.encoder.layer.6.attn                  
INFO:           q= 3.8027 k= 3.8027 v= 3.8027 ->  3.8027
INFO:           q= 0.3149 k= 0.3149 v= 0.3149 ->  0.3149
INFO:           q= 3.7988 k= 3.7988 v= 3.7988 ->  3.7988
INFO: FUSE_QKV: transformer.encoder.layer.7.attn                  
INFO:           q= 4.3320 k= 4.3320 v= 4.3320 ->  4.3320
INFO:           q= 0.3098 k= 0.3098 v= 0.3098 ->  0.3098
INFO:           q= 4.3203 k= 4.3203 v= 4.3203 ->  4.3203
INFO: FUSE_QKV: transformer.encoder.layer.8.attn                  
INFO:           q= 4.7812 k= 4.7812 v= 4.7812 ->  4.7812
INFO:           q= 0.3306 k= 0.3306 v= 0.3306 ->  0.3306
INFO:           q= 4.7695 k= 4.7695 v= 4.7695 ->  4.7695
INFO: FUSE_QKV: transformer.encoder.layer.9.attn                  
INFO:           q= 4.8398 k= 4.8398 v= 4.8398 ->  4.8398
INFO:           q= 0.3450 k= 0.3450 v= 0.3450 ->  0.3450
INFO:           q= 4.8164 k= 4.8164 v= 4.8164 ->  4.8164
INFO: FUSE_QKV: transformer.encoder.layer.10.attn                 
INFO:           q= 4.8320 k= 4.8320 v= 4.8320 ->  4.8320
INFO:           q= 0.2988 k= 0.2988 v= 0.2988 ->  0.2988
INFO:           q= 4.8281 k= 4.8281 v= 4.8281 ->  4.8281
INFO: FUSE_QKV: transformer.encoder.layer.11.attn                 
INFO:           q= 4.6211 k= 4.6211 v= 4.6211 ->  4.6211
INFO:           q= 0.3125 k= 0.3125 v= 0.3125 ->  0.3125
INFO:           q= 4.6250 k= 4.6250 v= 4.6250 ->  4.6250
transformer.encoder.layer.0.ffn.fc1._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=3.6992 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.ffn.fc1._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.3303 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.0.ffn.fc1._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=4.7734 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.ffn.fc2._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=1.7480 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.ffn.fc2._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.5498 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.0.ffn.fc2._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=1.7637 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.query._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=1.7871 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.query._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3530 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.query._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=4.6016 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.key._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=1.7871 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.key._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.3530 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.key._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.6016 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.value._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=1.7871 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.value._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3530 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.value._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=4.6016 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.out._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=1.0840 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.out._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.2358 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.out._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.5723 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.matmul_q_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.6758 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.matmul_k_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.6758 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.matmul_v_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.6758 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.matmul_a_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.5781 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.attn.softmax_input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=88.5625 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.0.layernorm_input1_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.0.add1_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.0.add1_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.0.layernorm_input2_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.0.add2_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.0.add2_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.1.ffn.fc1._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=5.4375 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.ffn.fc1._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.3552 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.1.ffn.fc1._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=4.6445 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.ffn.fc2._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=2.1523 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.ffn.fc2._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.2878 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.1.ffn.fc2._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=1.0186 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.query._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=1.9199 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.query._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3779 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.query._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=3.9648 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.key._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=1.9199 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.key._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.3779 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.key._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.9648 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.value._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=1.9199 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.value._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3779 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.value._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=3.9648 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.out._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.9595 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.out._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.1979 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.out._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.5918 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.matmul_q_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.0234 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.matmul_k_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.0234 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.matmul_v_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.0234 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.matmul_a_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.1895 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.attn.softmax_input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=76.7500 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.1.layernorm_input1_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.1.add1_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.1.add1_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.1.layernorm_input2_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.1.add2_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.1.add2_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.2.ffn.fc1._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=4.0859 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.ffn.fc1._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.4753 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.2.ffn.fc1._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=4.6602 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.ffn.fc2._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=1.9746 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.ffn.fc2._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.3857 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.2.ffn.fc2._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.8560 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.query._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=2.7188 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.query._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3115 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.query._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=3.5762 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.key._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=2.7188 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.key._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.3115 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.key._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.5762 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.value._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=2.7188 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.value._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3115 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.value._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=3.5762 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.out._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.9653 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.out._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.2128 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.out._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.6284 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.matmul_q_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.6328 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.matmul_k_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.6328 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.matmul_v_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.6328 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.matmul_a_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.1339 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.attn.softmax_input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=59.5625 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.2.layernorm_input1_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.2.add1_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.2.add1_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.2.layernorm_input2_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.2.add2_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.2.add2_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.3.ffn.fc1._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=4.2578 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.ffn.fc1._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.2507 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.3.ffn.fc1._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=4.7617 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.ffn.fc2._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=2.1855 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.ffn.fc2._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.4033 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.3.ffn.fc2._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=1.0225 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.query._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=3.4219 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.query._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3596 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.query._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=3.2988 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.key._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=3.4219 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.key._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.3596 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.key._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.2988 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.value._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=3.4219 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.value._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3596 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.value._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=3.2988 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.out._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.8301 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.out._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.1760 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.out._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.5635 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.matmul_q_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.3457 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.matmul_k_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.3457 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.matmul_v_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.3457 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.matmul_a_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.0971 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.attn.softmax_input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=52.6562 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.3.layernorm_input1_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.3.add1_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.3.add1_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.3.layernorm_input2_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.3.add2_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.3.add2_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.4.ffn.fc1._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=4.1836 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.ffn.fc1._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.3787 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.4.ffn.fc1._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=4.7500 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.ffn.fc2._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=2.0508 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.ffn.fc2._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.3630 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.4.ffn.fc2._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.8877 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.query._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=5.0977 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.query._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3701 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.query._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=3.2891 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.key._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=5.0977 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.key._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.3701 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.key._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.2891 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.value._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=5.0977 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.value._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3701 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.value._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=3.2891 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.out._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.8081 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.out._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.1677 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.out._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.5049 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.matmul_q_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.2832 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.matmul_k_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.2832 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.matmul_v_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.2832 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.matmul_a_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.0722 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.attn.softmax_input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=54.2500 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.4.layernorm_input1_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.4.add1_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.4.add1_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.4.layernorm_input2_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.4.add2_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.4.add2_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.5.ffn.fc1._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=4.2891 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.ffn.fc1._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.2686 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.5.ffn.fc1._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=4.4219 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.ffn.fc2._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=1.9561 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.ffn.fc2._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.3423 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.5.ffn.fc2._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=1.5352 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.query._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=6.6289 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.query._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3071 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.query._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=3.3535 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.key._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=6.6289 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.key._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.3071 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.key._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.3535 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.value._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=6.6289 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.value._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3071 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.value._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=3.3535 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.out._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.6069 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.out._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.1541 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.out._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.4648 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.matmul_q_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.3574 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.matmul_k_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.3574 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.matmul_v_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.3574 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.matmul_a_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.0494 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.attn.softmax_input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=52.9375 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.5.layernorm_input1_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.5.add1_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.5.add1_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.5.layernorm_input2_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.5.add2_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.5.add2_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.6.ffn.fc1._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=3.9941 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.ffn.fc1._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.6050 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.6.ffn.fc1._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=4.2578 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.ffn.fc2._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=1.4102 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.ffn.fc2._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.2649 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.6.ffn.fc2._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.7861 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.query._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=8.3516 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.query._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3149 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.query._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=3.7988 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.key._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=8.3516 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.key._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.3149 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.key._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.7988 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.value._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=8.3516 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.value._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3149 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.value._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=3.7988 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.out._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.6377 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.out._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.2002 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.out._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.6436 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.matmul_q_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.8027 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.matmul_k_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.8027 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.matmul_v_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.8027 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.matmul_a_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.0474 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.attn.softmax_input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=56.7812 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.6.layernorm_input1_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.6.add1_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.6.add1_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.6.layernorm_input2_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.6.add2_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.6.add2_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.7.ffn.fc1._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=4.3242 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.ffn.fc1._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.7212 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.7.ffn.fc1._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=4.5156 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.ffn.fc2._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=1.8926 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.ffn.fc2._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.6094 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.7.ffn.fc2._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.7695 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.query._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=8.6953 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.query._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3098 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.query._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=4.3203 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.key._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=8.6953 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.key._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.3098 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.key._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.3203 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.value._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=8.6953 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.value._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3098 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.value._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=4.3203 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.out._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.5459 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.out._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.1675 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.out._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.4624 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.matmul_q_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.3320 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.matmul_k_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.3320 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.matmul_v_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.3320 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.matmul_a_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.0734 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.attn.softmax_input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=66.3750 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.7.layernorm_input1_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.7.add1_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.7.add1_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.7.layernorm_input2_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.7.add2_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.7.add2_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.8.ffn.fc1._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=3.9375 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.ffn.fc1._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.3726 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.8.ffn.fc1._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=5.3125 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.ffn.fc2._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=2.8262 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.ffn.fc2._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.3438 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.8.ffn.fc2._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=1.3867 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.query._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=8.7266 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.query._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3306 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.query._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=4.7695 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.key._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=8.7266 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.key._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.3306 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.key._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.7695 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.value._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=8.7266 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.value._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3306 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.value._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=4.7695 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.out._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=1.9736 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.out._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.1719 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.out._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.6387 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.matmul_q_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.7812 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.matmul_k_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.7812 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.matmul_v_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.7812 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.matmul_a_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.0889 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.attn.softmax_input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=65.1875 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.8.layernorm_input1_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.8.add1_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.8.add1_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.8.layernorm_input2_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.8.add2_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.8.add2_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.9.ffn.fc1._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=3.6289 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.ffn.fc1._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.3835 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.9.ffn.fc1._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=4.7539 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.ffn.fc2._input_quantizer                             TensorQuantizer(8bit fake per-tensor amax=3.0391 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.ffn.fc2._weight_quantizer                            TensorQuantizer(8bit fake per-tensor amax=0.3914 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.9.ffn.fc2._aftergemm_quantizer                         TensorQuantizer(8bit fake per-tensor amax=6.1250 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.query._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=6.8477 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.query._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3450 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.query._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=4.8164 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.key._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=6.8477 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.key._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.3450 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.key._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.8164 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.value._input_quantizer                          TensorQuantizer(8bit fake per-tensor amax=6.8477 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.value._weight_quantizer                         TensorQuantizer(8bit fake per-tensor amax=0.3450 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.value._aftergemm_quantizer                      TensorQuantizer(8bit fake per-tensor amax=4.8164 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.out._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=1.2549 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.out._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.1643 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.out._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.9829 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.matmul_q_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.8398 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.matmul_k_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.8398 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.matmul_v_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.8398 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.matmul_a_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.1234 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.attn.softmax_input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=70.8750 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.9.layernorm_input1_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.9.add1_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.9.add1_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.9.layernorm_input2_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.9.add2_local_input_quantizer                           TensorQuantizer(disabled)
transformer.encoder.layer.9.add2_residual_input_quantizer                        TensorQuantizer(disabled)
transformer.encoder.layer.10.ffn.fc1._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=3.7695 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.ffn.fc1._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.4631 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.10.ffn.fc1._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=5.1289 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.ffn.fc2._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=2.7949 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.ffn.fc2._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.5044 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.10.ffn.fc2._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=3.9141 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.query._input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=5.6992 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.query._weight_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.2988 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.query._aftergemm_quantizer                     TensorQuantizer(8bit fake per-tensor amax=4.8281 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.key._input_quantizer                           TensorQuantizer(8bit fake per-tensor amax=5.6992 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.key._weight_quantizer                          TensorQuantizer(8bit fake per-tensor amax=0.2988 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.key._aftergemm_quantizer                       TensorQuantizer(8bit fake per-tensor amax=4.8281 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.value._input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=5.6992 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.value._weight_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.2988 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.value._aftergemm_quantizer                     TensorQuantizer(8bit fake per-tensor amax=4.8281 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.out._input_quantizer                           TensorQuantizer(8bit fake per-tensor amax=3.5625 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.out._weight_quantizer                          TensorQuantizer(8bit fake per-tensor amax=0.1990 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.out._aftergemm_quantizer                       TensorQuantizer(8bit fake per-tensor amax=0.9209 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.matmul_q_input_quantizer                       TensorQuantizer(8bit fake per-tensor amax=4.8320 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.matmul_k_input_quantizer                       TensorQuantizer(8bit fake per-tensor amax=4.8320 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.matmul_v_input_quantizer                       TensorQuantizer(8bit fake per-tensor amax=4.8320 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.matmul_a_input_quantizer                       TensorQuantizer(8bit fake per-tensor amax=0.0746 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.attn.softmax_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=200.2500 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.10.layernorm_input1_quantizer                          TensorQuantizer(disabled)
transformer.encoder.layer.10.add1_local_input_quantizer                          TensorQuantizer(disabled)
transformer.encoder.layer.10.add1_residual_input_quantizer                       TensorQuantizer(disabled)
transformer.encoder.layer.10.layernorm_input2_quantizer                          TensorQuantizer(disabled)
transformer.encoder.layer.10.add2_local_input_quantizer                          TensorQuantizer(disabled)
transformer.encoder.layer.10.add2_residual_input_quantizer                       TensorQuantizer(disabled)
transformer.encoder.layer.11.ffn.fc1._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=3.8945 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.ffn.fc1._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.4395 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.11.ffn.fc1._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=5.6953 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.ffn.fc2._input_quantizer                            TensorQuantizer(8bit fake per-tensor amax=2.2480 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.ffn.fc2._weight_quantizer                           TensorQuantizer(8bit fake per-tensor amax=0.5142 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.11.ffn.fc2._aftergemm_quantizer                        TensorQuantizer(8bit fake per-tensor amax=4.9062 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.query._input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=3.7637 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.query._weight_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.3125 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.query._aftergemm_quantizer                     TensorQuantizer(8bit fake per-tensor amax=4.6250 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.key._input_quantizer                           TensorQuantizer(8bit fake per-tensor amax=3.7637 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.key._weight_quantizer                          TensorQuantizer(8bit fake per-tensor amax=0.3125 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.key._aftergemm_quantizer                       TensorQuantizer(8bit fake per-tensor amax=4.6250 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.value._input_quantizer                         TensorQuantizer(8bit fake per-tensor amax=3.7637 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.value._weight_quantizer                        TensorQuantizer(8bit fake per-tensor amax=0.3125 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.value._aftergemm_quantizer                     TensorQuantizer(8bit fake per-tensor amax=4.6250 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.out._input_quantizer                           TensorQuantizer(8bit fake per-tensor amax=3.5176 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.out._weight_quantizer                          TensorQuantizer(8bit fake per-tensor amax=0.2947 calibrator=MaxCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.out._aftergemm_quantizer                       TensorQuantizer(8bit fake per-tensor amax=2.5801 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.matmul_q_input_quantizer                       TensorQuantizer(8bit fake per-tensor amax=4.6211 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.matmul_k_input_quantizer                       TensorQuantizer(8bit fake per-tensor amax=4.6211 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.matmul_v_input_quantizer                       TensorQuantizer(8bit fake per-tensor amax=4.6211 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.matmul_a_input_quantizer                       TensorQuantizer(8bit fake per-tensor amax=0.0614 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.attn.softmax_input_quantizer                        TensorQuantizer(8bit fake per-tensor amax=287.0000 calibrator=HistogramCalibrator scale=1.0 quant)
transformer.encoder.layer.11.layernorm_input1_quantizer                          TensorQuantizer(disabled)
transformer.encoder.layer.11.add1_local_input_quantizer                          TensorQuantizer(disabled)
transformer.encoder.layer.11.add1_residual_input_quantizer                       TensorQuantizer(disabled)
transformer.encoder.layer.11.layernorm_input2_quantizer                          TensorQuantizer(disabled)
transformer.encoder.layer.11.add2_local_input_quantizer                          TensorQuantizer(disabled)
transformer.encoder.layer.11.add2_residual_input_quantizer                       TensorQuantizer(disabled)
         276/         348 ( 79.31%) TensorQuantizers enabled
    84934656/    97619072 ( 87.01%) Quantized weights
          88/    97619072 (  0.00%) Zero weights
    97619072/    98185797 ( 99.42%) Weight parameters



OrderedDict([('active.all.allocated', 6895), ('active.all.current', 710), ('active.all.freed', 6185), ('active.all.peak', 724), ('active.large_pool.allocated', 1652), ('active.large_pool.current', 85), ('active.large_pool.freed', 1567), ('active.large_pool.peak', 99), ('active.small_pool.allocated', 5243), ('active.small_pool.current', 625), ('active.small_pool.freed', 4618), ('active.small_pool.peak', 629), ('active_bytes.all.allocated', 530216478208), ('active_bytes.all.current', 619423232), ('active_bytes.all.freed', 529597054976), ('active_bytes.all.peak', 10162798080), ('active_bytes.large_pool.allocated', 530001418752), ('active_bytes.large_pool.current', 594480128), ('active_bytes.large_pool.freed', 529406938624), ('active_bytes.large_pool.peak', 10137857024), ('active_bytes.small_pool.allocated', 215059456), ('active_bytes.small_pool.current', 24943104), ('active_bytes.small_pool.freed', 190116352), ('active_bytes.small_pool.peak', 27048448), ('allocated_bytes.all.allocated', 530216478208), ('allocated_bytes.all.current', 619423232), ('allocated_bytes.all.freed', 529597054976), ('allocated_bytes.all.peak', 10162798080), ('allocated_bytes.large_pool.allocated', 530001418752), ('allocated_bytes.large_pool.current', 594480128), ('allocated_bytes.large_pool.freed', 529406938624), ('allocated_bytes.large_pool.peak', 10137857024), ('allocated_bytes.small_pool.allocated', 215059456), ('allocated_bytes.small_pool.current', 24943104), ('allocated_bytes.small_pool.freed', 190116352), ('allocated_bytes.small_pool.peak', 27048448), ('allocation.all.allocated', 6895), ('allocation.all.current', 710), ('allocation.all.freed', 6185), ('allocation.all.peak', 724), ('allocation.large_pool.allocated', 1652), ('allocation.large_pool.current', 85), ('allocation.large_pool.freed', 1567), ('allocation.large_pool.peak', 99), ('allocation.small_pool.allocated', 5243), ('allocation.small_pool.current', 625), ('allocation.small_pool.freed', 4618), ('allocation.small_pool.peak', 629), ('inactive_split.all.allocated', 2633), ('inactive_split.all.current', 21), ('inactive_split.all.freed', 2612), ('inactive_split.all.peak', 29), ('inactive_split.large_pool.allocated', 819), ('inactive_split.large_pool.current', 19), ('inactive_split.large_pool.freed', 800), ('inactive_split.large_pool.peak', 26), ('inactive_split.small_pool.allocated', 1814), ('inactive_split.small_pool.current', 2), ('inactive_split.small_pool.freed', 1812), ('inactive_split.small_pool.peak', 5), ('inactive_split_bytes.all.allocated', 276756768256), ('inactive_split_bytes.all.current', 51665408), ('inactive_split_bytes.all.freed', 276705102848), ('inactive_split_bytes.all.peak', 2164778496), ('inactive_split_bytes.large_pool.allocated', 276240239104), ('inactive_split_bytes.large_pool.current', 51442688), ('inactive_split_bytes.large_pool.freed', 276188796416), ('inactive_split_bytes.large_pool.peak', 2163045376), ('inactive_split_bytes.small_pool.allocated', 516529152), ('inactive_split_bytes.small_pool.current', 222720), ('inactive_split_bytes.small_pool.freed', 516306432), ('inactive_split_bytes.small_pool.peak', 2192896), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 13665042432), ('reserved_bytes.all.current', 13665042432), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 13665042432), ('reserved_bytes.large_pool.allocated', 13637779456), ('reserved_bytes.large_pool.current', 13637779456), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 13637779456), ('reserved_bytes.small_pool.allocated', 27262976), ('reserved_bytes.small_pool.current', 27262976), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 27262976), ('segment.all.allocated', 43), ('segment.all.current', 43), ('segment.all.freed', 0), ('segment.all.peak', 43), ('segment.large_pool.allocated', 30), ('segment.large_pool.current', 30), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 30), ('segment.small_pool.allocated', 13), ('segment.small_pool.current', 13), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 13)])
OrderedDict([('active.all.allocated', 47775), ('active.all.current', 710), ('active.all.freed', 47065), ('active.all.peak', 728), ('active.large_pool.allocated', 14762), ('active.large_pool.current', 85), ('active.large_pool.freed', 14677), ('active.large_pool.peak', 99), ('active.small_pool.allocated', 33013), ('active.small_pool.current', 625), ('active.small_pool.freed', 32388), ('active.small_pool.peak', 631), ('active_bytes.all.allocated', 5810765035008), ('active_bytes.all.current', 619423232), ('active_bytes.all.freed', 5810145611776), ('active_bytes.all.peak', 10162802176), ('active_bytes.large_pool.allocated', 5809654380032), ('active_bytes.large_pool.current', 594480128), ('active_bytes.large_pool.freed', 5809059899904), ('active_bytes.large_pool.peak', 10137857024), ('active_bytes.small_pool.allocated', 1110654976), ('active_bytes.small_pool.current', 24943104), ('active_bytes.small_pool.freed', 1085711872), ('active_bytes.small_pool.peak', 27052544), ('allocated_bytes.all.allocated', 5810765035008), ('allocated_bytes.all.current', 619423232), ('allocated_bytes.all.freed', 5810145611776), ('allocated_bytes.all.peak', 10162802176), ('allocated_bytes.large_pool.allocated', 5809654380032), ('allocated_bytes.large_pool.current', 594480128), ('allocated_bytes.large_pool.freed', 5809059899904), ('allocated_bytes.large_pool.peak', 10137857024), ('allocated_bytes.small_pool.allocated', 1110654976), ('allocated_bytes.small_pool.current', 24943104), ('allocated_bytes.small_pool.freed', 1085711872), ('allocated_bytes.small_pool.peak', 27052544), ('allocation.all.allocated', 47775), ('allocation.all.current', 710), ('allocation.all.freed', 47065), ('allocation.all.peak', 728), ('allocation.large_pool.allocated', 14762), ('allocation.large_pool.current', 85), ('allocation.large_pool.freed', 14677), ('allocation.large_pool.peak', 99), ('allocation.small_pool.allocated', 33013), ('allocation.small_pool.current', 625), ('allocation.small_pool.freed', 32388), ('allocation.small_pool.peak', 631), ('inactive_split.all.allocated', 21565), ('inactive_split.all.current', 22), ('inactive_split.all.freed', 21543), ('inactive_split.all.peak', 32), ('inactive_split.large_pool.allocated', 7829), ('inactive_split.large_pool.current', 19), ('inactive_split.large_pool.freed', 7810), ('inactive_split.large_pool.peak', 27), ('inactive_split.small_pool.allocated', 13736), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 13733), ('inactive_split.small_pool.peak', 7), ('inactive_split_bytes.all.allocated', 3235484719616), ('inactive_split_bytes.all.current', 51665408), ('inactive_split_bytes.all.freed', 3235433054208), ('inactive_split_bytes.all.peak', 2519259648), ('inactive_split_bytes.large_pool.allocated', 3232852836864), ('inactive_split_bytes.large_pool.current', 51442688), ('inactive_split_bytes.large_pool.freed', 3232801394176), ('inactive_split_bytes.large_pool.peak', 2517234688), ('inactive_split_bytes.small_pool.allocated', 2631882752), ('inactive_split_bytes.small_pool.current', 222720), ('inactive_split_bytes.small_pool.freed', 2631660032), ('inactive_split_bytes.small_pool.peak', 2192896), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 13665042432), ('reserved_bytes.all.current', 13665042432), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 13665042432), ('reserved_bytes.large_pool.allocated', 13637779456), ('reserved_bytes.large_pool.current', 13637779456), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 13637779456), ('reserved_bytes.small_pool.allocated', 27262976), ('reserved_bytes.small_pool.current', 27262976), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 27262976), ('segment.all.allocated', 43), ('segment.all.current', 43), ('segment.all.freed', 0), ('segment.all.peak', 43), ('segment.large_pool.allocated', 30), ('segment.large_pool.current', 30), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 30), ('segment.small_pool.allocated', 13), ('segment.small_pool.current', 13), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 13)])
OrderedDict([('active.all.allocated', 88655), ('active.all.current', 710), ('active.all.freed', 87945), ('active.all.peak', 728), ('active.large_pool.allocated', 27872), ('active.large_pool.current', 85), ('active.large_pool.freed', 27787), ('active.large_pool.peak', 99), ('active.small_pool.allocated', 60783), ('active.small_pool.current', 625), ('active.small_pool.freed', 60158), ('active.small_pool.peak', 631), ('active_bytes.all.allocated', 11091313591808), ('active_bytes.all.current', 619423232), ('active_bytes.all.freed', 11090694168576), ('active_bytes.all.peak', 10162802176), ('active_bytes.large_pool.allocated', 11089307341312), ('active_bytes.large_pool.current', 594480128), ('active_bytes.large_pool.freed', 11088712861184), ('active_bytes.large_pool.peak', 10137857024), ('active_bytes.small_pool.allocated', 2006250496), ('active_bytes.small_pool.current', 24943104), ('active_bytes.small_pool.freed', 1981307392), ('active_bytes.small_pool.peak', 27052544), ('allocated_bytes.all.allocated', 11091313591808), ('allocated_bytes.all.current', 619423232), ('allocated_bytes.all.freed', 11090694168576), ('allocated_bytes.all.peak', 10162802176), ('allocated_bytes.large_pool.allocated', 11089307341312), ('allocated_bytes.large_pool.current', 594480128), ('allocated_bytes.large_pool.freed', 11088712861184), ('allocated_bytes.large_pool.peak', 10137857024), ('allocated_bytes.small_pool.allocated', 2006250496), ('allocated_bytes.small_pool.current', 24943104), ('allocated_bytes.small_pool.freed', 1981307392), ('allocated_bytes.small_pool.peak', 27052544), ('allocation.all.allocated', 88655), ('allocation.all.current', 710), ('allocation.all.freed', 87945), ('allocation.all.peak', 728), ('allocation.large_pool.allocated', 27872), ('allocation.large_pool.current', 85), ('allocation.large_pool.freed', 27787), ('allocation.large_pool.peak', 99), ('allocation.small_pool.allocated', 60783), ('allocation.small_pool.current', 625), ('allocation.small_pool.freed', 60158), ('allocation.small_pool.peak', 631), ('inactive_split.all.allocated', 39900), ('inactive_split.all.current', 22), ('inactive_split.all.freed', 39878), ('inactive_split.all.peak', 32), ('inactive_split.large_pool.allocated', 14839), ('inactive_split.large_pool.current', 19), ('inactive_split.large_pool.freed', 14820), ('inactive_split.large_pool.peak', 27), ('inactive_split.small_pool.allocated', 25061), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 25058), ('inactive_split.small_pool.peak', 7), ('inactive_split_bytes.all.allocated', 6194212670976), ('inactive_split_bytes.all.current', 51665408), ('inactive_split_bytes.all.freed', 6194161005568), ('inactive_split_bytes.all.peak', 2519259648), ('inactive_split_bytes.large_pool.allocated', 6189465434624), ('inactive_split_bytes.large_pool.current', 51442688), ('inactive_split_bytes.large_pool.freed', 6189413991936), ('inactive_split_bytes.large_pool.peak', 2517234688), ('inactive_split_bytes.small_pool.allocated', 4747236352), ('inactive_split_bytes.small_pool.current', 222720), ('inactive_split_bytes.small_pool.freed', 4747013632), ('inactive_split_bytes.small_pool.peak', 2192896), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 13665042432), ('reserved_bytes.all.current', 13665042432), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 13665042432), ('reserved_bytes.large_pool.allocated', 13637779456), ('reserved_bytes.large_pool.current', 13637779456), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 13637779456), ('reserved_bytes.small_pool.allocated', 27262976), ('reserved_bytes.small_pool.current', 27262976), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 27262976), ('segment.all.allocated', 43), ('segment.all.current', 43), ('segment.all.freed', 0), ('segment.all.peak', 43), ('segment.large_pool.allocated', 30), ('segment.large_pool.current', 30), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 30), ('segment.small_pool.allocated', 13), ('segment.small_pool.current', 13), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 13)])
OrderedDict([('active.all.allocated', 129535), ('active.all.current', 710), ('active.all.freed', 128825), ('active.all.peak', 728), ('active.large_pool.allocated', 40982), ('active.large_pool.current', 85), ('active.large_pool.freed', 40897), ('active.large_pool.peak', 99), ('active.small_pool.allocated', 88553), ('active.small_pool.current', 625), ('active.small_pool.freed', 87928), ('active.small_pool.peak', 631), ('active_bytes.all.allocated', 16371862148608), ('active_bytes.all.current', 619423232), ('active_bytes.all.freed', 16371242725376), ('active_bytes.all.peak', 10162802176), ('active_bytes.large_pool.allocated', 16368960302592), ('active_bytes.large_pool.current', 594480128), ('active_bytes.large_pool.freed', 16368365822464), ('active_bytes.large_pool.peak', 10137857024), ('active_bytes.small_pool.allocated', 2901846016), ('active_bytes.small_pool.current', 24943104), ('active_bytes.small_pool.freed', 2876902912), ('active_bytes.small_pool.peak', 27052544), ('allocated_bytes.all.allocated', 16371862148608), ('allocated_bytes.all.current', 619423232), ('allocated_bytes.all.freed', 16371242725376), ('allocated_bytes.all.peak', 10162802176), ('allocated_bytes.large_pool.allocated', 16368960302592), ('allocated_bytes.large_pool.current', 594480128), ('allocated_bytes.large_pool.freed', 16368365822464), ('allocated_bytes.large_pool.peak', 10137857024), ('allocated_bytes.small_pool.allocated', 2901846016), ('allocated_bytes.small_pool.current', 24943104), ('allocated_bytes.small_pool.freed', 2876902912), ('allocated_bytes.small_pool.peak', 27052544), ('allocation.all.allocated', 129535), ('allocation.all.current', 710), ('allocation.all.freed', 128825), ('allocation.all.peak', 728), ('allocation.large_pool.allocated', 40982), ('allocation.large_pool.current', 85), ('allocation.large_pool.freed', 40897), ('allocation.large_pool.peak', 99), ('allocation.small_pool.allocated', 88553), ('allocation.small_pool.current', 625), ('allocation.small_pool.freed', 87928), ('allocation.small_pool.peak', 631), ('inactive_split.all.allocated', 58235), ('inactive_split.all.current', 22), ('inactive_split.all.freed', 58213), ('inactive_split.all.peak', 32), ('inactive_split.large_pool.allocated', 21849), ('inactive_split.large_pool.current', 19), ('inactive_split.large_pool.freed', 21830), ('inactive_split.large_pool.peak', 27), ('inactive_split.small_pool.allocated', 36386), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 36383), ('inactive_split.small_pool.peak', 7), ('inactive_split_bytes.all.allocated', 9152940622336), ('inactive_split_bytes.all.current', 51665408), ('inactive_split_bytes.all.freed', 9152888956928), ('inactive_split_bytes.all.peak', 2519259648), ('inactive_split_bytes.large_pool.allocated', 9146078032384), ('inactive_split_bytes.large_pool.current', 51442688), ('inactive_split_bytes.large_pool.freed', 9146026589696), ('inactive_split_bytes.large_pool.peak', 2517234688), ('inactive_split_bytes.small_pool.allocated', 6862589952), ('inactive_split_bytes.small_pool.current', 222720), ('inactive_split_bytes.small_pool.freed', 6862367232), ('inactive_split_bytes.small_pool.peak', 2192896), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 13665042432), ('reserved_bytes.all.current', 13665042432), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 13665042432), ('reserved_bytes.large_pool.allocated', 13637779456), ('reserved_bytes.large_pool.current', 13637779456), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 13637779456), ('reserved_bytes.small_pool.allocated', 27262976), ('reserved_bytes.small_pool.current', 27262976), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 27262976), ('segment.all.allocated', 43), ('segment.all.current', 43), ('segment.all.freed', 0), ('segment.all.peak', 43), ('segment.large_pool.allocated', 30), ('segment.large_pool.current', 30), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 30), ('segment.small_pool.allocated', 13), ('segment.small_pool.current', 13), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 13)])
OrderedDict([('active.all.allocated', 170415), ('active.all.current', 710), ('active.all.freed', 169705), ('active.all.peak', 728), ('active.large_pool.allocated', 54092), ('active.large_pool.current', 85), ('active.large_pool.freed', 54007), ('active.large_pool.peak', 99), ('active.small_pool.allocated', 116323), ('active.small_pool.current', 625), ('active.small_pool.freed', 115698), ('active.small_pool.peak', 631), ('active_bytes.all.allocated', 21652410705408), ('active_bytes.all.current', 619423232), ('active_bytes.all.freed', 21651791282176), ('active_bytes.all.peak', 10162802176), ('active_bytes.large_pool.allocated', 21648613263872), ('active_bytes.large_pool.current', 594480128), ('active_bytes.large_pool.freed', 21648018783744), ('active_bytes.large_pool.peak', 10137857024), ('active_bytes.small_pool.allocated', 3797441536), ('active_bytes.small_pool.current', 24943104), ('active_bytes.small_pool.freed', 3772498432), ('active_bytes.small_pool.peak', 27052544), ('allocated_bytes.all.allocated', 21652410705408), ('allocated_bytes.all.current', 619423232), ('allocated_bytes.all.freed', 21651791282176), ('allocated_bytes.all.peak', 10162802176), ('allocated_bytes.large_pool.allocated', 21648613263872), ('allocated_bytes.large_pool.current', 594480128), ('allocated_bytes.large_pool.freed', 21648018783744), ('allocated_bytes.large_pool.peak', 10137857024), ('allocated_bytes.small_pool.allocated', 3797441536), ('allocated_bytes.small_pool.current', 24943104), ('allocated_bytes.small_pool.freed', 3772498432), ('allocated_bytes.small_pool.peak', 27052544), ('allocation.all.allocated', 170415), ('allocation.all.current', 710), ('allocation.all.freed', 169705), ('allocation.all.peak', 728), ('allocation.large_pool.allocated', 54092), ('allocation.large_pool.current', 85), ('allocation.large_pool.freed', 54007), ('allocation.large_pool.peak', 99), ('allocation.small_pool.allocated', 116323), ('allocation.small_pool.current', 625), ('allocation.small_pool.freed', 115698), ('allocation.small_pool.peak', 631), ('inactive_split.all.allocated', 76570), ('inactive_split.all.current', 22), ('inactive_split.all.freed', 76548), ('inactive_split.all.peak', 32), ('inactive_split.large_pool.allocated', 28859), ('inactive_split.large_pool.current', 19), ('inactive_split.large_pool.freed', 28840), ('inactive_split.large_pool.peak', 27), ('inactive_split.small_pool.allocated', 47711), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 47708), ('inactive_split.small_pool.peak', 7), ('inactive_split_bytes.all.allocated', 12111668573696), ('inactive_split_bytes.all.current', 51665408), ('inactive_split_bytes.all.freed', 12111616908288), ('inactive_split_bytes.all.peak', 2519259648), ('inactive_split_bytes.large_pool.allocated', 12102690630144), ('inactive_split_bytes.large_pool.current', 51442688), ('inactive_split_bytes.large_pool.freed', 12102639187456), ('inactive_split_bytes.large_pool.peak', 2517234688), ('inactive_split_bytes.small_pool.allocated', 8977943552), ('inactive_split_bytes.small_pool.current', 222720), ('inactive_split_bytes.small_pool.freed', 8977720832), ('inactive_split_bytes.small_pool.peak', 2192896), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 13665042432), ('reserved_bytes.all.current', 13665042432), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 13665042432), ('reserved_bytes.large_pool.allocated', 13637779456), ('reserved_bytes.large_pool.current', 13637779456), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 13637779456), ('reserved_bytes.small_pool.allocated', 27262976), ('reserved_bytes.small_pool.current', 27262976), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 27262976), ('segment.all.allocated', 43), ('segment.all.current', 43), ('segment.all.freed', 0), ('segment.all.peak', 43), ('segment.large_pool.allocated', 30), ('segment.large_pool.current', 30), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 30), ('segment.small_pool.allocated', 13), ('segment.small_pool.current', 13), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 13)])
OrderedDict([('active.all.allocated', 211295), ('active.all.current', 710), ('active.all.freed', 210585), ('active.all.peak', 728), ('active.large_pool.allocated', 67202), ('active.large_pool.current', 85), ('active.large_pool.freed', 67117), ('active.large_pool.peak', 99), ('active.small_pool.allocated', 144093), ('active.small_pool.current', 625), ('active.small_pool.freed', 143468), ('active.small_pool.peak', 631), ('active_bytes.all.allocated', 26932959262208), ('active_bytes.all.current', 619423232), ('active_bytes.all.freed', 26932339838976), ('active_bytes.all.peak', 10162802176), ('active_bytes.large_pool.allocated', 26928266225152), ('active_bytes.large_pool.current', 594480128), ('active_bytes.large_pool.freed', 26927671745024), ('active_bytes.large_pool.peak', 10137857024), ('active_bytes.small_pool.allocated', 4693037056), ('active_bytes.small_pool.current', 24943104), ('active_bytes.small_pool.freed', 4668093952), ('active_bytes.small_pool.peak', 27052544), ('allocated_bytes.all.allocated', 26932959262208), ('allocated_bytes.all.current', 619423232), ('allocated_bytes.all.freed', 26932339838976), ('allocated_bytes.all.peak', 10162802176), ('allocated_bytes.large_pool.allocated', 26928266225152), ('allocated_bytes.large_pool.current', 594480128), ('allocated_bytes.large_pool.freed', 26927671745024), ('allocated_bytes.large_pool.peak', 10137857024), ('allocated_bytes.small_pool.allocated', 4693037056), ('allocated_bytes.small_pool.current', 24943104), ('allocated_bytes.small_pool.freed', 4668093952), ('allocated_bytes.small_pool.peak', 27052544), ('allocation.all.allocated', 211295), ('allocation.all.current', 710), ('allocation.all.freed', 210585), ('allocation.all.peak', 728), ('allocation.large_pool.allocated', 67202), ('allocation.large_pool.current', 85), ('allocation.large_pool.freed', 67117), ('allocation.large_pool.peak', 99), ('allocation.small_pool.allocated', 144093), ('allocation.small_pool.current', 625), ('allocation.small_pool.freed', 143468), ('allocation.small_pool.peak', 631), ('inactive_split.all.allocated', 94905), ('inactive_split.all.current', 22), ('inactive_split.all.freed', 94883), ('inactive_split.all.peak', 32), ('inactive_split.large_pool.allocated', 35869), ('inactive_split.large_pool.current', 19), ('inactive_split.large_pool.freed', 35850), ('inactive_split.large_pool.peak', 27), ('inactive_split.small_pool.allocated', 59036), ('inactive_split.small_pool.current', 3), ('inactive_split.small_pool.freed', 59033), ('inactive_split.small_pool.peak', 7), ('inactive_split_bytes.all.allocated', 15070396525056), ('inactive_split_bytes.all.current', 51665408), ('inactive_split_bytes.all.freed', 15070344859648), ('inactive_split_bytes.all.peak', 2519259648), ('inactive_split_bytes.large_pool.allocated', 15059303227904), ('inactive_split_bytes.large_pool.current', 51442688), ('inactive_split_bytes.large_pool.freed', 15059251785216), ('inactive_split_bytes.large_pool.peak', 2517234688), ('inactive_split_bytes.small_pool.allocated', 11093297152), ('inactive_split_bytes.small_pool.current', 222720), ('inactive_split_bytes.small_pool.freed', 11093074432), ('inactive_split_bytes.small_pool.peak', 2192896), ('max_split_size', -1), ('num_alloc_retries', 0), ('num_ooms', 0), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('reserved_bytes.all.allocated', 13665042432), ('reserved_bytes.all.current', 13665042432), ('reserved_bytes.all.freed', 0), ('reserved_bytes.all.peak', 13665042432), ('reserved_bytes.large_pool.allocated', 13637779456), ('reserved_bytes.large_pool.current', 13637779456), ('reserved_bytes.large_pool.freed', 0), ('reserved_bytes.large_pool.peak', 13637779456), ('reserved_bytes.small_pool.allocated', 27262976), ('reserved_bytes.small_pool.current', 27262976), ('reserved_bytes.small_pool.freed', 0), ('reserved_bytes.small_pool.peak', 27262976), ('segment.all.allocated', 43), ('segment.all.current', 43), ('segment.all.freed', 0), ('segment.all.peak', 43), ('segment.large_pool.allocated', 30), ('segment.large_pool.current', 30), ('segment.large_pool.freed', 0), ('segment.large_pool.peak', 30), ('segment.small_pool.allocated', 13), ('segment.small_pool.current', 13), ('segment.small_pool.freed', 0), ('segment.small_pool.peak', 13)])
Validation time: 122.73539662361145
